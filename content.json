{"meta":{"title":"fudali","subtitle":"do one`s best","description":"do one`s best APE","author":"fudali","url":"http://fudali.cc"},"pages":[{"title":"关于我","date":"2016-12-12T16:00:00.000Z","updated":"2017-03-17T09:39:12.000Z","comments":true,"path":"about/index.html","permalink":"http://fudali.cc/about/index.html","excerpt":"","text":"hi, i am a sunshine boy ^_^ my cool photo loading error These are my hobby: sports , basketball coding running beautiful girl fork me github"},{"title":"","date":"2017-03-17T08:41:11.000Z","updated":"2017-03-17T08:41:11.000Z","comments":false,"path":"categories/index.html","permalink":"http://fudali.cc/categories/index.html","excerpt":"","text":""},{"title":"doob入门","date":"2016-01-12T16:00:00.000Z","updated":"2017-03-18T08:21:46.000Z","comments":true,"path":"doob/doob-get-start.html","permalink":"http://fudali.cc/doob/doob-get-start.html","excerpt":"","text":"快速开始下载依赖1go get github.com/fudali113/doob 创建main函数文件demo.go1234567891011121314package mainimport &quot;github.com/fudali113/doob&quot;func main() &#123; doob.Start(8888)&#125;func init()&#123; router := doob.DefaultRouter() router.Get(&quot;/test&quot;, func (ctx *doob.Context) interface&#123;&#125; &#123; return &quot;test&quot; &#125;)&#125; 编译运行1go run demo.go 浏览效果打开浏览器并访问 http://localhost:8888/test"},{"title":"doob micro-framework document","date":"2017-03-09T16:00:00.000Z","updated":"2017-03-25T20:32:01.000Z","comments":true,"path":"doob/index.html","permalink":"http://fudali.cc/doob/index.html","excerpt":"","text":"get start get start 简单的使用并运行起来 使用 路由使用"},{"title":"go错误类型","date":"2016-03-15T16:00:00.000Z","updated":"2017-03-26T07:43:01.000Z","comments":true,"path":"note/http.html","permalink":"http://fudali.cc/note/http.html","excerpt":"","text":"HEADER Transfer-Encoding: chunked 客服端将分段解析tcp发送的数据，以0结尾 URL ietf rfc3986 5.2.3 /出现在最右边是怎么处理 好难，感觉看不懂"},{"title":"go错误类型","date":"2016-03-15T16:00:00.000Z","updated":"2017-03-18T08:21:51.000Z","comments":true,"path":"note/go-error.html","permalink":"http://fudali.cc/note/go-error.html","excerpt":"","text":"引包错误12use of package sort without selector该错误出现在引入报名与当前包中定义的变量或函数重名"},{"title":"doob doc","date":"2017-03-09T16:00:00.000Z","updated":"2017-03-18T04:58:13.000Z","comments":true,"path":"note/index.html","permalink":"http://fudali.cc/note/index.html","excerpt":"","text":"golang 中的错误"},{"title":"rancher","date":"2016-03-15T16:00:00.000Z","updated":"2017-03-21T06:05:41.000Z","comments":true,"path":"note/rancher.html","permalink":"http://fudali.cc/note/rancher.html","excerpt":"","text":"建议 使用专用主机运行rancher服务"},{"title":"","date":"2017-03-17T08:40:51.000Z","updated":"2017-03-17T08:40:51.000Z","comments":false,"path":"tags/index.html","permalink":"http://fudali.cc/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"spring cloud 微服务异常记录与报警","slug":"spring-cloud-excepton-deal","date":"2017-11-01T16:00:00.000Z","updated":"2017-11-02T10:41:39.000Z","comments":true,"path":"2017/11/02/spring-cloud-excepton-deal/","link":"","permalink":"http://fudali.cc/2017/11/02/spring-cloud-excepton-deal/","excerpt":"","text":"前言当我们的应用在线上正常运转起来了，在正常情况下我们不需要再担心任何的事情，但是bug总是不可避免的会出现；此时我们就需要一种相关的机制能够发现我们系统中的异常并通知到相关人员，不然等到用户进行反馈时才能知道发生了bug是很影响用户体验的也是不可控的，这两者都是不可接受的。 介绍我所在的团队目前正在使用spring cloud相关套件进行微服务的开发，所以我的介绍与实践也是在该技术栈下进行，同时可能会使用到elasticsearch。我们使用spring mvc来进行业务开发，feign来做restful接口远程调用框架，zuul作为服务网关来对外开放接口。这个技术栈在使用spring cloud进行开发的团队是非常常见的。 思路因为最开始我们就有在网关记录统一的访问日志，并使用filebeat将其同步到elasticsearch以方便后期数据的查询与分析，但是只是这样子是不够的；我们想要直接能够从日志中能够判断是否发生了毕竟明确的异常，我们需要有一个点或者相关的阈值去确定什么情况是异常，可能会有bug，需要进行相关的操作去进行报警。所以我们需要在日志记录上面做一些文章，让我们记录的日志能够有足够有力和准确的信息让我们去判断是不是异常，然后去触发一系列的操作(报警等等…)。经过一定的分析之后我认为异常是一个很好的判断是否有bug的点，因为没有异常不一定没有bug，但是有没有被捕获异常的请求一定是有bug的；所以以此作为切入点，深入思考。 实现开发中的定制首先我们的基础架构指定了统一的错误码来对外进行提示，同时在业务层以抛出异常来对外进行提示。我们将它定义为：1234567891011121314151617public class DomainServerException extends Exception &#123; // 平台定义错误码 private int code; // http status private int status; // 具体错误信息，面向开发者的提示， Exception的message用于面向用户的提示 private int error; // 相关异常的堆栈信息 private int stack; public DomainServiceException(int code, String message, Throwable throwable) &#123; super(message, throwable); this.code = code; if (isServerError()) this.stack = ExceptionUtils.getStackTrace(throwable); &#125;&#125; 其中的stack信息就是为了我们进行异常追踪而添加的字段，当http status为5**或者平台定义错误码为服务器异常的时候会加载相关异常堆栈信息并设值到stack字段。具体是在DomainServiceException构造函数进行或者在spring ErrorController中进行相关设值操作(因为我们使用异常来抛出错误码，所以我们对spring MVC默认的ErrorController进行了定制)。我们ErrorController的返回类型定义为12345678910public class HttpErrorResponse implements Serializable &#123; private Date timestamp; private Integer status; private String error; private String message; private String stack; // 异常堆栈 方便记录同时在前后端调试的时候信息也更加丰富 private String exception; // 异常类型 private String path; // 错误请求路径 private Integer errorCode; // 平台定义错误码&#125; 对于错误的情况我们抛出DomainServerException或者其他未捕获异常，DomainServerException默认为我们的业务错误，同时也可作为异常错误，但是我们在进行异常错误处理为DomainServerException是会将上层异常堆栈传入构造函数生成DomainServerException异常对象(注意:此模式下一定不要去处理你不知道该怎么处理的异常，如果你处理不了就一直往外抛，ErroController能够正确的处理并记录他然后供报警使用)。此时我们抛出的HttpErrorResponse可能会被两个地方用到: 服务之间的调用 zuul转发来的请求 对于第一种情况，因为我们使用feign来进行服务间远程调用，我们重写了ErrorDecoder来进行HttpErrorResponse与DomainServerException或者DomainServerException的子类(通过exception字段来进行类型判断)并向外抛出。级联调用一次类推，最终都会到网关一层进行处理。所以第一种情况最终也会变为第二种情况。 对于第二种情况我们，因为我们有错误码的定义并且在正常情况下我们也会返回错误，但是正常的结果却是没有错误码的，所以我们在zuul实现了一个type为“post”的filter来对返回值进行格式化，同时也对老的平台与新的平台进行输出格式化。在这里面我们判断服务返回的内容是否有异常并进行相关的记录(存入相关信息到RequestContext)，最后在统一日志记录Filter(包含正常filter和zuul 异常filter)进行统一记录相关信息。同时因为我们在zuul也写了一些胶水接口，所以我们在Zuul继承了普通服务的ErroController实现了ZuulErrorController同时也会记录异常信息。 日志的储存和报警记录怎么样的日志已经确定了，我们使用filebeat来讲日志数据传输到elasticsearch中。现在我们elasticsearch中就有错误码和stack的信息了，很明显，stack信息是很明显的错误信息，紫瑶该字段一出现就表示我们的代码又问题，我们可以根据这个很好的去报警。对于错误码信息，可能会比较复杂，我们需要判断他在某些情况下的一个阈值，当我们在某种情况下相关错误码超过了该阈值就报警(目前该块的应用还需要多思考)对于elasticsearch查询报警的工具有elastalert,但是我对于该工具不是很感冒，同时我也疲于应对python部署那些复杂的依赖，我正在使用golang开发一款功能更简洁，学习成本更低的工具。如果在内部试用的还行应该会进行开源。 未完待续","categories":[{"name":"微服务 监控","slug":"微服务-监控","permalink":"http://fudali.cc/categories/微服务-监控/"}],"tags":[{"name":"spring cloud","slug":"spring-cloud","permalink":"http://fudali.cc/tags/spring-cloud/"}]},{"title":"zuul业务检查相关模块","slug":"zuul-biz-check","date":"2017-05-20T16:00:00.000Z","updated":"2017-05-21T13:01:26.000Z","comments":true,"path":"2017/05/21/zuul-biz-check/","link":"","permalink":"http://fudali.cc/2017/05/21/zuul-biz-check/","excerpt":"","text":"前言在使用spring cloud进行微服务开发的过程中，因为微服务之间的访问只是对资源的访问，不应该有权限相关的检验，但是对外开放的服务是必须要对没有用户所能访问的资源与操作进行权限检验的。而spring cloud的网关服务开源项目并没有很好地提供业务检查相关的处理模块，所以我在使用zuul进行网关开发的过程中根据自己的理解写了一套业务检查相关的代码。 简介业务相关的权限检查因为每个微服务所需要的检查是不一样的，所以不同的微服务可能需要不同的检查，且同意微服务内不同的接口路径和HTTP方法的检查策略也可能是不同的，所以检查应该可以确切到每一个访问。 业务检查虽然是在网关进行检查的，但是为了降低耦合与提高内聚。实际检查的处理逻辑也应该是由微服务内部提供，并对外提供接口。我们在网关进行检查的时候也应该是请求相关的接口检查权限。 zuul权限检查模块的实现思路大致是可以在配置文件中配置微服务相关路由的检查器(实现BusinessChecker接口的实现类)，根据检查内容抛出错误或者通过检查。 在代码的实现上时，提供BusinessChecker接口供需要检查的权限实现，拥有type(),order(),check(CheckContext ct)方法并且该接口默认实现了Comparable&lt;BusinessChecker&gt;, type :返回改checker的type，用于在配置文件中配置路由相关处理器的type时使用 order :返回执行时的顺序 check :进行实际的检查内容，一般以抛出异常为检验错误。 CheckContext :是从Zull requestContext 切换过来的上下文，主要是为了与Zuul的解耦 CheckException :检查时可抛出的错误，包含Http status, BizCode, 错误信息。 CheckManager :管理根据路由获取相关Checker的管理类，首先根据相关配置获取个Checker的type，在根据type查找在spring中的相关bean，最后排序并返回改请求所对应的相关Check实体数组。 BusinessVerifyFilter :主要是衔接Check模块与Zuul之间的桥梁 CheckProperties :加载相关的配置文件 代码zuul-biz-check","categories":[{"name":"微服务","slug":"微服务","permalink":"http://fudali.cc/categories/微服务/"}],"tags":[{"name":"spring cloud","slug":"spring-cloud","permalink":"http://fudali.cc/tags/spring-cloud/"},{"name":"zuul","slug":"zuul","permalink":"http://fudali.cc/tags/zuul/"}]},{"title":"4.22 thoughtWorks 学习","slug":"tw-learn-4.22","date":"2017-04-21T16:00:00.000Z","updated":"2017-04-22T03:01:11.000Z","comments":true,"path":"2017/04/22/tw-learn-4.22/","link":"","permalink":"http://fudali.cc/2017/04/22/tw-learn-4.22/","excerpt":"","text":"","categories":[{"name":"容器技术","slug":"容器技术","permalink":"http://fudali.cc/categories/容器技术/"}],"tags":[{"name":"学习","slug":"学习","permalink":"http://fudali.cc/tags/学习/"},{"name":"docker","slug":"docker","permalink":"http://fudali.cc/tags/docker/"}]},{"title":"springbox-swagger2使用","slug":"springbox-swagger2-conflict-feignclient","date":"2017-04-19T16:00:00.000Z","updated":"2017-05-04T09:44:47.000Z","comments":true,"path":"2017/04/20/springbox-swagger2-conflict-feignclient/","link":"","permalink":"http://fudali.cc/2017/04/20/springbox-swagger2-conflict-feignclient/","excerpt":"","text":"与FeignClient冲突 Q: 使用springbox-swagger2 2.2.2版本进行注释api生成文档，但是当basePackage路径下存在feignClient注释的类时，将会报NullPointerException.出现这种情况是因为2.2.2版本没有对feignClient初始化时调用refreshContext作兼容。 A: 升级版本到最新版，在2.5.0中改问题被彻底解决;springbox-swagger2 github issue 1074; “111-1141-9124”,”111-1143-6985”,”111-1145-2039”,”111-1144-0685”","categories":[{"name":"微服务","slug":"微服务","permalink":"http://fudali.cc/categories/微服务/"}],"tags":[{"name":"swagger","slug":"swagger","permalink":"http://fudali.cc/tags/swagger/"},{"name":"spring cloud","slug":"spring-cloud","permalink":"http://fudali.cc/tags/spring-cloud/"}]},{"title":"word pattern 实现","slug":"woed_pattern","date":"2017-04-14T16:00:00.000Z","updated":"2017-04-15T14:56:37.000Z","comments":true,"path":"2017/04/15/woed_pattern/","link":"","permalink":"http://fudali.cc/2017/04/15/woed_pattern/","excerpt":"","text":"简介leetcode第290题 代码go123456789101112131415161718192021222324252627func wordPattern(pattern string, str string) bool &#123; singleStrs := strings.Split(str, &quot; &quot;) if len(pattern) != len(singleStrs) &#123; return false &#125; for i := 0; i &lt; len(pattern); i++ &#123; singleP := pattern[i] singleStr := singleStrs[i] for j := 0; j &lt; len(pattern); j++ &#123; if i == j &#123; continue &#125; _singleP := pattern[j] _singleStr := singleStrs[j] if singleP == _singleP &amp;&amp; singleStr != _singleStr &#123; return false &#125; switch &#123; case singleP == _singleP &amp;&amp; singleStr != _singleStr: return false case singleP != _singleP &amp;&amp; singleStr == _singleStr: return false &#125; &#125; &#125; return true&#125;","categories":[{"name":"算法","slug":"算法","permalink":"http://fudali.cc/categories/算法/"}],"tags":[{"name":"学习","slug":"学习","permalink":"http://fudali.cc/tags/学习/"},{"name":"算法","slug":"算法","permalink":"http://fudali.cc/tags/算法/"},{"name":"leetcode","slug":"leetcode","permalink":"http://fudali.cc/tags/leetcode/"}]},{"title":"fastjson反序列化异常类","slug":"fastjson-desrialze-exception","date":"2017-03-28T16:00:00.000Z","updated":"2017-03-29T03:01:45.000Z","comments":true,"path":"2017/03/29/fastjson-desrialze-exception/","link":"","permalink":"http://fudali.cc/2017/03/29/fastjson-desrialze-exception/","excerpt":"","text":"简介因为公司本使用fastjson进行json数据序列化与反序列化。最近正准备实践微服务，可能需要在各服务之间传递异常，顾将异常信息序列化传输在反序列化。本以为fastjson根据setter进行反序列化相关操作，但是实际情况有些差距，我自定义的一些字段并没有被反序列化。 内容如下，我的异常结构体是：12345678910111213141516171819202122public class BaseException extends FeignException &#123; private int code; public BaseException()&#123; super(&quot;&quot;, null); &#125; protected BaseException(int code, String message, Throwable cause) &#123; super(message, cause); this.code = code; &#125; public int getCode() &#123; return code; &#125; public void setCode(int code) &#123; this.code = code; &#125;&#125; 我接收到的json数据是：123456&#123; &quot;code&quot;: 133, &quot;message&quot;: &quot;ooo&quot;, &quot;stackTrace&quot;: [...], &quot;rootCause&quot;: &#123;...&#125;&#125; 但是反序列化后我得到的实体却只有stackTrace信息，并没有code和message信息，只有debug追踪代码找原因。最后找到DefaultJSONParse.java12345678910111213141516171819202122232425262728293031public &lt;T&gt; T parseObject(Type type, Object fieldName) &#123; int token = lexer.token(); if (token == JSONToken.NULL) &#123; lexer.nextToken(); return null; &#125; if (token == JSONToken.LITERAL_STRING) &#123; if (type == byte[].class) &#123; byte[] bytes = lexer.bytesValue(); lexer.nextToken(); return (T) bytes; &#125; if (type == char[].class) &#123; String strVal = lexer.stringVal(); lexer.nextToken(); return (T) strVal.toCharArray(); &#125; &#125; // 这里会根据类型获取相关的反序列化类型，Exception Type对应ThrowableDeserializer反序列化类 ObjectDeserializer derializer = config.getDeserializer(type); try &#123; return (T) derializer.deserialze(this, type, fieldName); &#125; catch (JSONException e) &#123; throw e; &#125; catch (Throwable e) &#123; throw new JSONException(e.getMessage(), e); &#125; &#125; ThrowableDeserializer在初始化异常类的代码如下：123456789101112131415161718192021222324252627282930313233343536private Throwable createException(String message, Throwable cause, Class&lt;?&gt; exClass) throws Exception &#123; Constructor&lt;?&gt; defaultConstructor = null; Constructor&lt;?&gt; messageConstructor = null; Constructor&lt;?&gt; causeConstructor = null; for (Constructor&lt;?&gt; constructor : exClass.getConstructors()) &#123; Class&lt;?&gt;[] types = constructor.getParameterTypes(); if (types.length == 0) &#123; defaultConstructor = constructor; continue; &#125; if (types.length == 1 &amp;&amp; types[0] == String.class) &#123; messageConstructor = constructor; continue; &#125; if (types.length == 2 &amp;&amp; types[0] == String.class &amp;&amp; types[1] == Throwable.class) &#123; causeConstructor = constructor; continue; &#125; &#125; if (causeConstructor != null) &#123; return (Throwable) causeConstructor.newInstance(message, cause); &#125; if (messageConstructor != null) &#123; return (Throwable) messageConstructor.newInstance(message); &#125; if (defaultConstructor != null) &#123; return (Throwable) defaultConstructor.newInstance(); &#125; return null; &#125; 从最下面的三个if判断可以看出，ThrowableDeserializer是根据构造函数来进行初始化实体的且值支持三种类型，最开始我的构造函数只有无参构造满足最后一个，所以最后出来的数据都为空，除了堆栈。那堆栈为何不为空呢？因为在ThrowableDeserializer的deserialze()的最后有一段这样的代码123if (stackTrace != null) &#123; ex.setStackTrace(stackTrace); &#125; so… 总结使用fastjson反序列化Exception类时一定要给出确定的构造函数且与之对应。","categories":[{"name":"笔记","slug":"笔记","permalink":"http://fudali.cc/categories/笔记/"}],"tags":[{"name":"fastjson","slug":"fastjson","permalink":"http://fudali.cc/tags/fastjson/"}]},{"title":"排序-堆排序","slug":"heap-sort","date":"2017-03-24T16:00:00.000Z","updated":"2017-03-25T09:09:06.000Z","comments":true,"path":"2017/03/25/heap-sort/","link":"","permalink":"http://fudali.cc/2017/03/25/heap-sort/","excerpt":"","text":"简介堆排序是利用堆的特性实现的排序方式;因为最小堆始终保证堆顶元素为最小值，且每此获取操作为logN;顾堆排序为NlogN的时间复杂度 代码go12345678910111213package heapimport &quot;github.com/fudali113/learn-basic/adt&quot;// HeapSort 堆排序func HeapSort(array []int) &#123; arrayLen := len(array) minHeap := adt.GetHeap(false) minHeap.Insert(array...) for i := 0; i &lt; arrayLen; i++ &#123; array[i], _ = minHeap.Delete() &#125;&#125; 总结时间复杂度: NlogN是否稳定: 不稳定","categories":[{"name":"算法","slug":"算法","permalink":"http://fudali.cc/categories/算法/"}],"tags":[{"name":"golang","slug":"golang","permalink":"http://fudali.cc/tags/golang/"},{"name":"学习","slug":"学习","permalink":"http://fudali.cc/tags/学习/"},{"name":"排序","slug":"排序","permalink":"http://fudali.cc/tags/排序/"}]},{"title":"consul权限控制","slug":"consul-acl","date":"2017-03-23T16:00:00.000Z","updated":"2017-03-25T04:36:59.000Z","comments":true,"path":"2017/03/24/consul-acl/","link":"","permalink":"http://fudali.cc/2017/03/24/consul-acl/","excerpt":"","text":"前言最近公司准备实践微服务，在服务发现与注册方面选择了consul；主要是基于易用与功能全面的考虑； 因为之前只是有点点初步的理解，并没有去深入的了解与实践，实践的时候发现consul的权限控制有一点不好理解；所以只有跟我们老大(大波哥)一起去踩坑； 内容 consul的acl控制默认是关闭的，需要在任意配置文件中添加acl_master_token配置项 此时默认的控制策略是可写的(acl_default_policy为write) 因为consul默认有匿名token(即anonymous),此token当用户acl开启且用户token为空时默认使用该token 因为此时默认策略为全部可写，此时anonymous也拥有全部的权限包括acl的读写权限 顾想要设置权限控制应该使acl_default_policy为deny，此时默认权限控制为全部否定。 当配置之后可能会发现打开ui依然可见自己的consul服务，这一点会让人很奇怪，这是consul在检测服务时默认不检测consul服务的权限： consul/consul/acl.go#347 version：v0.7.5 1234567// allowService is used to determine if a service is accessible for an ACL.func (f *aclFilter) allowService(service string) bool &#123; if service == &quot;&quot; || service == ConsulServiceID &#123; return true &#125; return f.acl.ServiceRead(service)&#125; github issue # 2816 这个貌似可以使使用enforceVersion8进行控制，未实现 对于ui中多次输错token出现403页面，可以使用清除浏览器缓存或者换个浏览器进入ui界面，这应该做的一定的安全举措","categories":[{"name":"微服务","slug":"微服务","permalink":"http://fudali.cc/categories/微服务/"}],"tags":[{"name":"consul","slug":"consul","permalink":"http://fudali.cc/tags/consul/"}]},{"title":"数据结构-对顶堆","slug":"adt-median-heap","date":"2017-03-21T16:00:00.000Z","updated":"2017-03-22T14:58:25.000Z","comments":true,"path":"2017/03/22/adt-median-heap/","link":"","permalink":"http://fudali.cc/2017/03/22/adt-median-heap/","excerpt":"","text":"前言对顶堆，用于实时求解中位数用一个最大堆和一个最小堆组成一个结构体对插入元素进行操作并使最大堆元素与最少堆元素最多只能有一个交点(集两个堆顶相等)且保证两个堆的长度差距不能大于1 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798package adtimport &quot;log&quot;// MedianHeap 实时求解中位数堆type MedianHeap struct &#123; min *Heap max *Heap&#125;// GetMedianHeap 获取一个中位数堆func GetMedianHeap() MedianHeap &#123; return MedianHeap&#123;min: GetHeap(false), max: GetHeap(true)&#125;&#125;// Len 获取实际长度func (mh MedianHeap) Len() int &#123; return mh.min.Len() + mh.max.Len()&#125;// Insert 添加一个元素func (mh MedianHeap) Insert(value int) &#123; if mh.min.Len() == 0 &#123; mh.min.Insert(value) return &#125; if mh.max.Len() == 0 &#123; minValue, _ := mh.min.Get() if value &gt; minValue &#123; mh.min.Delete() mh.min.Insert(value) mh.max.Insert(minValue) &#125; else &#123; mh.max.Insert(value) &#125; return &#125; if mh.insertMin(value) &#123; mh.min.Insert(value) &#125; else &#123; mh.max.Insert(value) &#125; mh.reset()&#125;// GetMedian 实时获取中位数func (mh MedianHeap) GetMedian() (median float32) &#123; log.Println(&quot;GetMedian log:&quot;, mh.min, &quot;---&quot;, mh.max) minL, maxL := mh.min.Len(), mh.max.Len() if mh.Len() == 0 &#123; return 0 &#125; gap := minL - maxL switch gap &#123; case 1: minV, _ := mh.min.Get() median = float32(minV) case 0: minV, _ := mh.min.Get() maxV, _ := mh.max.Get() median = (float32(minV) + float32(maxV)) / 2 case -1: maxV, _ := mh.max.Get() median = float32(maxV) default: mh.reset() mh.GetMedian() &#125; return&#125;func (mh MedianHeap) insertMin(value int) bool &#123; minV, _ := mh.min.Get() maxV, _ := mh.max.Get() minL, maxL := mh.min.Len(), mh.max.Len() if value &gt; minV &#123; return true &#125; else if value &gt;= maxV &#123; if minL &gt; maxL &#123; return false &#125; return true &#125; return false&#125;func (mh MedianHeap) reset() &#123; minL, maxL := mh.min.Len(), mh.max.Len() gap := minL - maxL if gap &gt;= 2 &#123; minV, _ := mh.min.Delete() mh.max.Insert(minV) &#125; else if gap &lt;= -2 &#123; maxV, _ := mh.max.Delete() mh.min.Insert(maxV) &#125;&#125; golang code on github 总结TODO","categories":[{"name":"数据结构","slug":"数据结构","permalink":"http://fudali.cc/categories/数据结构/"}],"tags":[{"name":"golang","slug":"golang","permalink":"http://fudali.cc/tags/golang/"},{"name":"ADT","slug":"ADT","permalink":"http://fudali.cc/tags/ADT/"},{"name":"学习","slug":"学习","permalink":"http://fudali.cc/tags/学习/"}]},{"title":"数据结构-堆","slug":"adt-heap","date":"2017-03-19T16:00:00.000Z","updated":"2017-03-20T15:24:19.000Z","comments":true,"path":"2017/03/20/adt-heap/","link":"","permalink":"http://fudali.cc/2017/03/20/adt-heap/","excerpt":"","text":"前言堆又称为优先队列，支持插入和删除堆顶操作；分为最小堆、最大堆、还有一种扩展实现对顶堆，常用语实时获取中位数；在贪婪算法的实现即是基于堆，该算法通过反复最小元来进行操作； 下虑插入下虑插入主要用在delete操作，此时顶刚好空缺并且堆中少了一个元素,因此现在堆中最后一个元素(暂且命名为X)必须移动到该堆的某个位置。 如果X可以放入堆顶，那么delete操作完成。 但是这一般不太可能，因此我们将空缺位置的两个儿子中优先级(根据最大堆或者最小堆优先级可能不同)更大与空缺位置调换；此时空缺位置被推向想一层。重复改步鄹直到X可以放入空缺位置。 这种一般的策略叫做下虑； 下虑插入示意图 上虑插入上虑插入主要用于insert操作，此时堆中处于平衡状态，因此现在在堆尾建立一个一个空缺位置； 在空缺位置与其父节点进行对比优先级，若插入元素优先级更高，则将空缺位置与父节点调换位置； 此时空缺位置已被推上一层，重复吃步鄹直到找到合适的空缺位置。 这种一般的策略叫做上虑； 上虑插入示意图1 上虑插入示意图2 代码go123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155package adtimport &quot;fmt&quot;// Heap 堆结构// 数组形式为index为0的元素默认为空，总index为1元素开始// 方便定位元素// 即如往堆里插入1,2,3,4,5// 数组元素为[0,1,2,3,4,5]type Heap struct &#123; array []int isMax bool // 表示最大堆还是最小堆&#125;// GetHeap 获取一个Heap实列func GetHeap(isMax bool) *Heap &#123; return &amp;Heap&#123;array: make([]int, 1, 8), isMax: isMax&#125;&#125;// Insert 插入一个元素func (h *Heap) Insert(value int) &#123; if h.array == nil &#123; h.array = make([]int, 1, 8) &#125; h.array = insert(h.array, value, h.isMax)&#125;// Delete 删除并获取堆顶func (h *Heap) Delete() (top int, err error) &#123; h.array, top, err = reset(h.array, h.isMax) return top, err&#125;// getCompareResult 比较func getCompareResult(o1, o2 int, isMax bool) int &#123; if o1 == o2 &#123; return 0 &#125; if isMax &#123; if o1 &gt; o2 &#123; return 1 &#125; return -1 &#125; if o1 &lt; o2 &#123; return 1 &#125; return -1&#125;////// Insert 相关函数////// insert 根据堆性质想数组中插入一个元素func insert(array []int, value int, isMax bool) (nowArray []int) &#123; nowArray = append(array, 0) insertIndex := getInsertIndex(nowArray, len(array), value, isMax) nowArray[insertIndex] = value return nowArray&#125;// getInsertIndex 递归获取插入元素的数组下标// 使用上虑策略func getInsertIndex(array []int, nowIndex int, value int, isMax bool) int &#123; if nowIndex &lt; 2 &#123; return 1 &#125; faIndex := getFaIndex(nowIndex) if getCompareResult(array[faIndex], value, isMax) &gt;= 0 &#123; return nowIndex &#125; array[faIndex], array[nowIndex] = array[nowIndex], array[faIndex] return getInsertIndex(array, faIndex, value, isMax)&#125;// getFaIndex 获取一个元素的父级元素数组下标func getFaIndex(index int) int &#123; return index / 2&#125;////// Delete 相关函数////const ( noGo = iota goLeft goRight)// reset 重设置一个数组func reset(array []int, isMax bool) (nowArray []int, topValue int, err error) &#123; lastIndex := len(array) - 1 if lastIndex == 1 &#123; topValue = array[1] nowArray = array[:lastIndex] return &#125; else if lastIndex &lt; 1 &#123; return array, 0, fmt.Errorf(&quot;堆中已无元素&quot;) &#125; topValue, array[1] = array[1], 0 value := array[len(array)-1] nowArray = array[:len(array)-1] lastInsertIndex := getLastInsertIndex(nowArray, 1, value, isMax) nowArray[lastInsertIndex] = value return&#125;// getLastInsertIndex 下虑func getLastInsertIndex(array []int, nowIndex int, value int, isMax bool) int &#123; status := noGo lastIndex := len(array) - 1 leftIndex, rightIndex := getSonIndex(nowIndex) if lastIndex &gt;= rightIndex &#123; left, right := array[leftIndex], array[rightIndex] status = getStatus(left, right, value, isMax) &#125; else if lastIndex == leftIndex &amp;&amp; getCompareResult(array[leftIndex], value, isMax) &gt;= 0 &#123; status = goLeft &#125; switch status &#123; case noGo: return nowIndex case goLeft: array[nowIndex], array[leftIndex] = array[leftIndex], value return getLastInsertIndex(array, leftIndex, value, isMax) case goRight: array[nowIndex], array[rightIndex] = array[rightIndex], value return getLastInsertIndex(array, rightIndex, value, isMax) &#125; panic(&quot;--&quot;)&#125;// getSonIndex 获取一个元素的左右子元素数组下标func getSonIndex(index int) (left, right int) &#123; return 2 * index, 2*index + 1&#125;// getStatus 根据三个值获取走那边获取步鄹func getStatus(left, right, value int, isMax bool) (res int) &#123; res = 0 if getCompareResult(left, value, isMax) &gt; 0 || getCompareResult(right, value, isMax) &gt; 0 &#123; res++ &#125; else &#123; return &#125; if getCompareResult(right, left, isMax) &gt; 0 &#123; res++ &#125; return&#125; golang code on github 总结插入时间复杂度：O(logN) 堆的实现确实惊为天人，如何的有魅力。特别是上虑与下虑策略的思想，真是让人大开眼界。","categories":[{"name":"数据结构","slug":"数据结构","permalink":"http://fudali.cc/categories/数据结构/"}],"tags":[{"name":"golang","slug":"golang","permalink":"http://fudali.cc/tags/golang/"},{"name":"ADT","slug":"ADT","permalink":"http://fudali.cc/tags/ADT/"},{"name":"学习","slug":"学习","permalink":"http://fudali.cc/tags/学习/"}]},{"title":"linux常用知识","slug":"linux","date":"2017-03-19T16:00:00.000Z","updated":"2017-03-20T09:14:08.000Z","comments":true,"path":"2017/03/20/linux/","link":"","permalink":"http://fudali.cc/2017/03/20/linux/","excerpt":"","text":"内核日志1cat /var/log/messages linux内存不足时kill进程策略OOM_killer是Linux自我保护的方式，在内存不足时将被唤醒，调出/proc/{pid}/oom_score最大者并将之kill掉 为了保护重要进程不被OOM_killer kill掉，可以配置/proc/{pid}/oom_score_adj,此值为内核在为每个进行打分时的附加值，最后得分等于实际值+该值顾可以使用echo -20 &gt; /proc/{pid}/oom_score_adj为实际值减去20(最后得分越小越不易被杀掉) root进程默认获取-30的附加值详细来源，从源码的角度讲解计算oom_score的函数linux源码 获取进程oom_score脚本1234567#!/bin/bashfor proc in $(find /proc -maxdepth 1 -regex &apos;/proc/[0-9]+&apos;); do printf &quot;%2d %5d %s\\n&quot; \\ &quot;$(cat $proc/oom_score)&quot; \\ &quot;$(basename $proc)&quot; \\ &quot;$(cat $proc/cmdline | tr &apos;\\0&apos; &apos; &apos; | head -c 50)&quot;done 2&gt;/dev/null | sort -nr | head -n 10","categories":[{"name":"linux","slug":"linux","permalink":"http://fudali.cc/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://fudali.cc/tags/linux/"}]},{"title":"排序知识总结","slug":"sort","date":"2017-03-19T16:00:00.000Z","updated":"2017-03-25T09:09:43.000Z","comments":true,"path":"2017/03/20/sort/","link":"","permalink":"http://fudali.cc/2017/03/20/sort/","excerpt":"","text":"排序算法稳定性假定在待排序的记录序列中，存在多个具有相同的关键字的记录，若经过排序，这些记录的相对次序保持不变，即在原序列中，ri=rj，且ri在rj之前，而在排序后的序列中，ri仍在rj之前，则称这种排序算法是稳定的；否则称为不稳定的。 对于不稳定的排序算法，只要举出一个实例，即可说明它的不稳定性；而对于稳定的排序算法，必须对算法进行分析从而得到稳定的特性。需要注意的是，排序算法是否为稳定的是由具体算法决定的，不稳定的算法在某种条件下可以变为稳定的算法，而稳定的算法在某种条件下也可以变为不稳定的算法。 堆排序、快速排序、希尔排序、直接选择排序不是稳定的排序算法，而基数排序、冒泡排序、直接插入排序、折半插入排序、归并排序是稳定的排序算法。 各算法时间复杂度与是否稳定 各算法时间复杂度与是否稳定对照表 资源掘金算法文章,包含各种算法","categories":[{"name":"算法","slug":"算法","permalink":"http://fudali.cc/categories/算法/"}],"tags":[{"name":"golang","slug":"golang","permalink":"http://fudali.cc/tags/golang/"},{"name":"学习","slug":"学习","permalink":"http://fudali.cc/tags/学习/"},{"name":"排序","slug":"排序","permalink":"http://fudali.cc/tags/排序/"}]},{"title":"排序-快速排序","slug":"quick-sort","date":"2017-03-17T16:00:00.000Z","updated":"2017-03-20T15:24:08.000Z","comments":true,"path":"2017/03/18/quick-sort/","link":"","permalink":"http://fudali.cc/2017/03/18/quick-sort/","excerpt":"","text":"前言快速排序是实践中一种快速的排序方式；他的平均运行时间是O(NlogN)，最坏运行时间是O(N^2)，但稍加努力可使最坏情形极难出现。并且可通过与堆排序的结果，可以使几乎所有的输入都能达到快速排序的快速运行时间。 简介快速排序可划分为简单的四个步骤(设输入数组为array)： 如果array中元素是0或者1，直接返回 取array中任一元素pivot，称之为枢纽元(pivot) 将array中不包含pivot按与pivot的比较大小划分成连个不相交的集合 递归对划分的两个合集进行该四步走并获得返回值与pivot合并成返回数组 代码go123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990package quick// QuickSort 快速排序// 是否稳定?// 不稳定 可以试着分析下[5,1,2,2,3,4,5]func QuickSort(array []int) &#123; quickSort(array, 0, len(array))&#125;// quickSort 快速排序私有递归方法func quickSort(array []int, left, right int) &#123; if right-left &lt; 2 &#123; return &#125; medianIndex := median3(array, left, right) nowMedianIndex := swap(array, left, right, medianIndex) quickSort(array, left, nowMedianIndex) quickSort(array, nowMedianIndex+1, right)&#125;// swap 按最开始的中位置下标将数组分为比中位置大和比中位值小的两个数组// left right 遵循右开左闭// return 划分后的中位值下标func swap(array []int, left, right, medianIndex int) (nowMedianIndex int) &#123; median := array[medianIndex] array[medianIndex], array[right-1] = array[right-1], median leftPoint := left rightPoint := right - 2 leftStop := false rightStop := false for &#123; // 如果左滑动指针停止，不做任何操作，等待右滑动指针也停止交换 if !leftStop &#123; if array[leftPoint] &lt;= median &#123; leftPoint++ &#125; else &#123; leftStop = true &#125; &#125; if !rightStop &#123; if array[rightPoint] &gt;= median &#123; rightPoint-- &#125; else &#123; rightStop = true &#125; &#125; //当左滑动指针与右滑动指针相交后，左滑动指针位置一定处于大于等于中位值的位置 if leftPoint &gt; rightPoint &#123; array[leftPoint], array[right-1] = array[right-1], array[leftPoint] nowMedianIndex = leftPoint return &#125; // 如果都停止，交换位置并重启滑动 if leftStop &amp;&amp; rightStop &#123; array[leftPoint], array[rightPoint] = array[rightPoint], array[leftPoint] leftStop, rightStop = false, false &#125; &#125;&#125;// median3 三数中值分割法// 比较数组开头，结尾和中间位置的值，放回处于中间的值得数组下标// return 中位值数组下标func median3(array []int, left, right int) int &#123; index := (right + left - 1) / 2 start := array[left] median := array[index] end := array[right-1] if median &gt; start &#123; if median &lt;= end &#123; return index &#125; else if end &gt;= start &#123; return right - 1 &#125; else &#123; return left &#125; &#125; else &#123; if median &gt;= end &#123; return index &#125; else if start &gt;= end &#123; return right - 1 &#125; else &#123; return left &#125; &#125;&#125; golang code on github 总结平均运行时间：O(NlogN)最坏运行时间：O(N^2)是否稳定：不稳定，试着分析[5,1,2,2,3,4,5]即可找到123456789101112131415161718选取枢纽元为2，是枢纽元到数组末尾5 1 2 5 3 4 2i j进行第一次交换的地方5 1 2 5 3 4 2i j第一次交换过后1 5 2 5 3 4 2j i此时 i &gt; j 将枢纽元从末尾与i位置元素调换1 2 2 5 3 4 5此时作为枢纽元的2从最开始的index=3变成了index=1跑到了与之相等的index为2的元素的前面，值为5的元素也发生了相似的状况顾快速排序为不稳定的排序","categories":[{"name":"算法","slug":"算法","permalink":"http://fudali.cc/categories/算法/"}],"tags":[{"name":"golang","slug":"golang","permalink":"http://fudali.cc/tags/golang/"},{"name":"学习","slug":"学习","permalink":"http://fudali.cc/tags/学习/"},{"name":"排序","slug":"排序","permalink":"http://fudali.cc/tags/排序/"}]},{"title":"tcp和udp网络协议","slug":"tcp-and-udp-protocols","date":"2017-03-16T16:00:00.000Z","updated":"2017-03-18T04:56:12.000Z","comments":true,"path":"2017/03/17/tcp-and-udp-protocols/","link":"","permalink":"http://fudali.cc/2017/03/17/tcp-and-udp-protocols/","excerpt":"","text":"简介TCP和UDP协议是IP网络中不同终端间通讯的两种传输协议。在OSI模型中，TCP、UDP是传输层协议，其中TCP是面向连接的协议，UDP是无连接的协议。 TCP什么是TCP 是传输层的一种面向连接的协议 处理下层的不可靠数据使之变得可靠(确定通过网络发送的数据报的状态并且如果部分已被丢弃则处理信息的重发的任务并按正确的顺序重新组合成消息以提供可靠性) TCP驻留在传输层中，并仅驻留在实际处理数据报的机器上，确保数据报已从源机器到目标机器；它不驻留在简单路由数据报的设备上，因此网关中没有TCP层。 tcp协议留驻在传输层示意图 TCP的特点 单播协议:TCP基于单播网络模型，支持两方之间的数据交换。它不支持广播或多播网络模型。 连接状态:TCP使用两个端点之间的同步状态，而不是在网络内强加一个状态来支持连接。该同步状态被设置为初始连接过程的一部分，因此TCP可以被认为是面向连接的协议。许多协议设计旨在确保每个本地状态转换被传送到远程方并由其确认。 可靠性: 可靠性意味着在连接的一端传递给TCP驱动程序的八位字节流将通过网络传输，使得流作为相同的八位字节序列呈现给远程进程，顺序与生成的由发送方。这意味着协议检测数据流的分段何时已被网络丢弃，重新排序，复制或损坏。在必要的情况下，发送器将重传损坏的段，以便允许接收器重建原始数据流。这意味着TCP发送方必须保持所有发送数据的本地副本，直到它接收到接收方已经完成数据的准确传送的指示为止。 全双工: TCP是全双工协议; 它允许双方在单个TCP连接的上下文内发送和接收数据。 流: 虽然TCP使用分组结构用于网络传输，但TCP是真正的流传输协议，并且应用级网络操作不透明。一些协议明确地封装每个应用事务;对于每一次写，都必须有一个匹配的读。以这种方式，在网络上保留数据流到逻辑记录结构的应用派生分段。TCP不保留施加在数据流上的这种隐式结构，使得在网络协议内的写和读操作之间不存在配对。例如，TCP应用可以将三个数据块按顺序写入网络连接，其可以由远程读取器在单个读取操作中收集。TCP会话中使用的数据块（段）的大小在会话开始时协商。发送器尝试在接收器的最大段大小，配置的发送器的最大段大小和最大可支持的非分段分组大小的限制内使用它可以用于数据传输的最大段大小网络路径（路径最大传输单元[MTU]）。路径MTU周期性地刷新以适应在TCP连接活动时可能发生在网络内的任何改变。 速率适配: TCP也是速率自适应协议，因为数据传输速率旨在适应网络内的主要负载条件并适应接收机的处理能力。没有预定的TCP数据传输速率; 如果网络和接收器都具有额外的可用容量，则TCP发送器将尝试向网络注入更多数据以占用此可用空间。相反，如果有拥塞，TCP发送方将降低其发送速率以允许网络恢复。该适配功能试图实现最高可能的数据传输速率，而不触发一致的数据丢失。 TCP建立连接三次握手客户端发送SYN消息; 服务器发送组合对客户端的SYN的ACK并且包含服务器的SYN的消息; 然后客户端发送对服务器的SYN的ACK。 建立连接步鄹图 连接在其生命周期中经过一系列状态: 侦听，SYN发送，SYN接收，建立，FIN-WAIT-1，FIN-WAIT-2，CLOSE-等待，CLOSING，LAST-ACK，TIME-WAIT和虚构状态CLOSED。CLOSED是虚构的，因为它代表没有TCP时的状态，因此没有连接。123456789101112131415161718192021LISTEN - 表示等待来自任何远程TCP和端口的连接请求。SYN-SENT - 表示在发送连接请求之后等待匹配的连接请求。SYN-RECEIVED - 表示在接收和发送连接请求之后等待确认连接请求确认。ESTABLISHED - 表示打开连接，收到的数据可以传递给用户。连接的数据传输阶段的正常状态。FIN-WAIT-1表示等待来自远程TCP的连接终止请求，或者先前发送的连接终止请求的确认。FIN-WAIT-2 - 表示等待来自远程TCP的连接终止请求。CLOSE-WAIT - 表示等待来自本地用户的连接终止请求。CLOSING - 表示等待来自远程TCP的连接终止请求确认。LAST-ACK-表示等待先前发送到远程TCP的连接终止请求的确认（其包括对其连接终止请求的确认）。TIME-WAIT - 表示等待足够的时间通过，以确保远程TCP接收到其连接终止请求的确认。CLOSED - 根本不表示连接状态。 TCP连接响应事件从一个状态进行到另一个状态。事件是用户调用，OPEN，SEND，RECEIVE，CLOSE，ABORT和STATUS; 传入段，特别是包含SYN，ACK，RST和FIN标志的段; 和超时。 连接建立和终止 建立连接 只有在两个机器之间的连接不存在，两个机器都同意连接，并且两个机器都有足够的TCP资源来为连接提供服务时，才能在两台机器之间建立连接。如果不满足这些条件中的任何一个，则不能进行连接。连接的接受可以由应用或系统管理例程触发。 数据传输 对于由机器A的TCP从ULP接收的每个数据块，TCP封装它并且以递增的序列号将其发送到机器B. 在机器B接收到消息之后，它使用增加下一个序列号的分段确认来确认它（并且因此指示它接收到该序列号的一切）。 tcp传输图 TCP数据传输服务实际上体现了六个不同的子服务： 全双工：使连接的两端在任何时间，甚至同时发送。 及时性：使用计时器可确保在合理的时间内传输数据。 有序：从一个应用程序发送的数据将在另一端以相同的顺序接收。这发生，尽管事实上数据报可能通过IP被无序地接收，因为TCP在将消息传递到较高层之前以正确的顺序重新组装消息。 标签：所有连接具有商定的优先级和安全值。 受控流：TCP可以通过使用缓冲区和窗口限制来调节信息流。 错误校正：校验和确保数据没有错误（在校验和算法的限制内）。 关闭连接为了关闭连接，TCP之一从ULP接收关闭原语并发出具有设置为开的FIN标志的消息。 tcp关闭连接示意图 在图中，机器A的TCP发送请求以关闭具有下一个序列号的机器B的连接。机器B然后将发送对该请求及其下一个序列号的确认。随后，机器B通过其ULP将关闭消息发送到应用程序，并等待应用程序确认关闭。这一步不是绝对必要的; TCP可以在没有应用程序批准的情况下关闭连接，但是一个良好的系统会通知应用程序状态的改变 UDP什么是UDP UDP是无连接和不可靠的传输协议。两个端口用于标识源和目标机器内的端点。当不需要可靠的传递时，使用用户数据报协议来代替TCP。然而，UDP从不用于发送诸如网页，数据库信息等重要数据。流式媒体例如视频，音频和其他使用UDP因为它提供速度。 UDP的特性 端到端。UDP可以识别在计算机上运行的特定进程。 不可靠，无连接传递（例如USPS:UDP使用无连接通信设置。在这个UDP中不需要在发送数据之前建立连接。通信仅由数据段本身组成）。 与IP相同的尽力语义 无ack，无序列，无流量控制 丢失，复制，延迟，无序或丢失连接 快速，低开销 因为以上特性udp更适合: 适合可靠的本地网络 RTP（实时传输协议 摘要UDP是传输层协议。UDP是一种无连接和不可靠的协议。UDP不做流量控制，错误控制或重传坏段。UDP比TCP快。UDP通常用于流音频和视频。UDP从未用于重要的文档，如网页，数据库信息等。UDP传输由8字节头组成的段。它包含源端口，目标端口，UDP长度和校验和。UDP校验和用于检测传输段中的“错误”。 TCP VS UDP 用户数据报协议（UDP）和传输控制协议（TCP）是TCP / IP协议组中传输层的“同级”。它们执行相同的角色，提供应用程序和Internet协议（IP）的数据移动功能之间的接口，但是它们以非常不同的方式实现。因此，这两种协议为高层协议提供了选择，允许每个协议根据其需要选择适当的协议。 有助于说明这两种协议的最重要的基本属性以及它们如何彼此对比的表： tcp&udp比较图","categories":[{"name":"网络协议","slug":"网络协议","permalink":"http://fudali.cc/categories/网络协议/"}],"tags":[{"name":"学习","slug":"学习","permalink":"http://fudali.cc/tags/学习/"},{"name":"网络","slug":"网络","permalink":"http://fudali.cc/tags/网络/"},{"name":"tcp/ip","slug":"tcp-ip","permalink":"http://fudali.cc/tags/tcp-ip/"}]},{"title":"排序-归并排序","slug":"merge-sort","date":"2017-03-16T16:00:00.000Z","updated":"2017-03-20T15:24:38.000Z","comments":true,"path":"2017/03/17/merge-sort/","link":"","permalink":"http://fudali.cc/2017/03/17/merge-sort/","excerpt":"","text":"前言归并排序体现了递归分治的策略思想是将数组拆分为两段，在对两段进行想通操作，直到数组元素为1，在对数组进行排序合并 代码go1234567891011121314151617181920212223242526272829303132333435package merge// MergeSort 归并排序func MergeSort(array []int) []int &#123; middle := len(array) / 2 if middle &lt; 1 &#123; return array &#125; return merge(MergeSort(array[:middle]), MergeSort(array[middle:]))&#125;// merge 合并两个排好序的数组唯一组合两个元素并排好序的数组func merge(a1 []int, a2 []int) []int &#123; a1Index := 0 a2Index := 0 res := make([]int, 0, len(a1)+len(a2)) for &#123; if a1[a1Index] &lt;= a2[a2Index] &#123; res = append(res, a1[a1Index]) if a1Index == len(a1)-1 &#123; res = append(res, a2[a2Index:]...) break &#125; a1Index++ &#125; else &#123; res = append(res, a2[a2Index]) if a2Index == len(a1)-1 &#123; res = append(res, a1[a1Index:]...) break &#125; a2Index++ &#125; &#125; return res&#125; golang code on github 总结虽然归并排序的运行时间是O(NlogN)，但是他合并两个已排序数组到一个附加数组会更占用内存。 与其他O(NlogN)的流行算法相比，归并排序是比较元素最少的，且运行时间严重依赖于比较元素和在数组(已经临时数组)中移动元素的开销(理论上使用更少内存的算法是可能的，但所得到的算法是复杂的和不实际的)。 这些开销是于语言相关的(java中泛型数组中的元素是引用类型的，顾移动元素开销不大，所以归并排序是java泛型数组的默认排序方式。 快速排序作为基础类型的排序方式，java基础类型是值传递的，因为比较与数据移动的开销是类似的，快排使用少得多的数据移动足以补偿那些附加的比较而且还有盈余)。 在go中也存在相同的问题，所以在不同的输入数据选择不同的排序方式再能得到最好的性能。 平均运行时间：O(NlogN)最坏运行时间：O(NlogN)是否稳定：稳定","categories":[{"name":"算法","slug":"算法","permalink":"http://fudali.cc/categories/算法/"}],"tags":[{"name":"golang","slug":"golang","permalink":"http://fudali.cc/tags/golang/"},{"name":"学习","slug":"学习","permalink":"http://fudali.cc/tags/学习/"},{"name":"排序","slug":"排序","permalink":"http://fudali.cc/tags/排序/"}]},{"title":"排序-希尔排序","slug":"shell-sort","date":"2017-03-14T16:00:00.000Z","updated":"2017-03-20T15:24:43.000Z","comments":true,"path":"2017/03/15/shell-sort/","link":"","permalink":"http://fudali.cc/2017/03/15/shell-sort/","excerpt":"","text":"前言个人认为希尔排序是对插入排序的一种优化，他利用一定的算法来决定每趟遍历比较两个元素之前的距离，最后的比较距离为1(此时等同于插入排序)。所以希尔排序也称为缩减增量排序他相比插入排序所在的优势是，他可以一次交换两个较远距离的元素，而插入排序交换两个相聚n的元素位子需要n次交换。 因为他根据一个算法来决定每趟比较的距离，所以该算法的好坏也会在一定程度上决定希尔排序的性能 代码go123456789101112131415161718192021222324package main// 利用每次除以2的等比增量数列来决定每趟比较距离func sort(array []int) &#123; n := 0 arrayLen := len(array) for gap := arrayLen / 2; gap &gt; 0; gap /= 2 &#123; for i := gap; i &lt; arrayLen; i++ &#123; iv := array[i] for j := i; j-gap &gt; 0 &amp;&amp; array[j-gap] &gt; iv; j -= gap &#123; n++ array[j-gap], array[j] = iv, array[j-gap] &#125; &#125; &#125; println(&quot;---------------&quot;, n)&#125;func main() &#123; array := []int&#123;10, 14, 73, 25, 23, 13, 27, 94, 33, 39, 25, 59, 94, 65, 82, 45&#125; sort(array) for _, v := range array &#123; println(v) &#125;&#125; golang code on github 总结希尔排序的性能在实践中的性能是完全可以接受的；使用希尔增量是最坏情形运行时间复杂度为O(N^2)对于好的增量序列，最坏时间复杂度还可以优化 编程的简单特点，使它成为对适度的大量输入数据进行排序的常用算法 最优运行时间：O(N)最坏运行时间：O(N^2)是否稳定：不稳定","categories":[{"name":"算法","slug":"算法","permalink":"http://fudali.cc/categories/算法/"}],"tags":[{"name":"golang","slug":"golang","permalink":"http://fudali.cc/tags/golang/"},{"name":"学习","slug":"学习","permalink":"http://fudali.cc/tags/学习/"},{"name":"排序","slug":"排序","permalink":"http://fudali.cc/tags/排序/"}]},{"title":"排序-插入排序","slug":"insertion-sort","date":"2017-03-12T16:00:00.000Z","updated":"2017-03-20T15:24:33.000Z","comments":true,"path":"2017/03/13/insertion-sort/","link":"","permalink":"http://fudali.cc/2017/03/13/insertion-sort/","excerpt":"","text":"前言 - 今天感觉受到了一些打击，感觉自己基础知识过于缺乏，顾决定从今日起，有空就写一篇博客，加强自己在算法与数据结构、网络、设计模式方面的知识 - 今天就想来理解一下排序算法中最简单的插入排序： 插入排序思路为顺序遍历数组，并在遍历中从顺序遍历到的元素倒序遍历回 倒序遍历是判断相邻两个元素是否符合排序规则 如果符合则停止倒序遍历 如果不符合则交换相邻两个元素位置并继续倒序遍历 代码实现go12345678910111213141516171819202122232425262728ppackage mainfunc sort(array []int) &#123; n := 0 // 从1开始遍历,因为0前面没有数值 for i := 1; i &lt; len(array); i++ &#123; // 在此处放置与在 代码1 处放置效果一样 // 因为若 jv &gt; iv 的话 ， j 与 j-1 调换位置， 下一次循环时 array[j] 依然是当初的 iv iv := array[i] for j := i; j &gt;= 0 &amp;&amp; array[j-1] &gt;= iv; j-- &#123; // 代码1 iv := array[j] // 如果 jv &gt; iv , 调换两个元素之间的位置 n++ array[j], array[j-1] = array[j-1], iv &#125; &#125; println(&quot;----------------&quot;, n)&#125;func main() &#123; array := []int&#123;10, 14, 73, 25, 23, 13, 27, 94, 33, 39, 25, 59, 94, 65, 82, 45&#125; sort(array) for _, v := range array &#123; println(v) &#125;&#125; golang code on github java 123456789101112131415161718192021222324252627282930public class Insertion &#123; public static void main(String[] args) &#123; Integer[] oo = new Integer[]&#123;34, 8, 64, 51, 32, 21&#125;; sort(oo); for (Integer var : oo) &#123; System.out.println(var); &#125; &#125; public static &lt;T&gt; void sort(T[] array) &#123; for (int i = 1; i&lt; array.length; i++) &#123; T it = array[i]; for (int j = i; j &gt; 0; j--) &#123; T jt = array[j - 1]; if (compare(jt, it) &lt; 0) &#123; break; &#125;else &#123; array[j] = jt; array[j - 1] = it; &#125; &#125; &#125; &#125; public static &lt;T&gt; int compare(T o1, T o2) &#123; return (Integer)o1 - (Integer)o2; &#125;&#125; java code on github 总结从原理和显示方式可以看出，当数组本就按排序规则排好序时，时间复杂度最小为 O(N)；当数组为倒序时未最坏情况，测试时间复杂度为O(N^2)当数组中根据排序规则倒序的元素对越多，时间复杂度越大，当数组根据排序规则完全倒序时，时间复杂度最大为 2+3+4+…+N = O(N) 平均运行时间：O(NlogN)最坏运行时间：O(NlogN)是否稳定：稳定","categories":[{"name":"算法","slug":"算法","permalink":"http://fudali.cc/categories/算法/"}],"tags":[{"name":"golang","slug":"golang","permalink":"http://fudali.cc/tags/golang/"},{"name":"学习","slug":"学习","permalink":"http://fudali.cc/tags/学习/"},{"name":"排序","slug":"排序","permalink":"http://fudali.cc/tags/排序/"}]},{"title":"ELK学习之安装logstash","slug":"ELK-install-logstash","date":"2017-02-15T16:00:00.000Z","updated":"2017-03-29T03:01:54.000Z","comments":true,"path":"2017/02/16/ELK-install-logstash/","link":"","permalink":"http://fudali.cc/2017/02/16/ELK-install-logstash/","excerpt":"","text":"下载安装 logstash基于jvm平台，所以安装前确认已安装jre 最新的logstash 5.*版本至少需要java8以上jre 对于Debian平台或者Redhat平台,官方推荐配置软件仓库并安装 Debian/Ubuntu 平台123456wget -O - http://packages.elasticsearch.org/GPG-KEY-elasticsearch | apt-key add -cat &gt;&gt; /etc/apt/sources.list &lt;&lt;EOFdeb http://packages.elasticsearch.org/logstash/5.0/debian stable mainEOFapt-get updateapt-get install logstash 一行一行复制输入命令行即可 有可能出现如下错误(也有可能是运行时出现)1Could not find any executable java binary. Please install java in your PATH or set JAVA_HOME. 此时需要修改logstash的启动配置文件，对Debian/Ubuntu系统，该文件路径为/etc/logstash/startup.options，其中的JAVACMD参数默认为/usr/**,顾导致找不到java命令，只需将改参数改为你的$JAVA_HOME/bin/java即可解决该错误 运行软件仓库安装后logstash bin所在路径为/usr/share/logstash 直接运行简单命令行输入input1bin/logstash -e &apos;input&#123;stdin&#123;&#125;&#125;output&#123;stdout&#123;codec=&gt;rubydebug&#125;&#125;&apos; 配置文件运行 1bin/logstash -f &#123;配置文件路径&#125;","categories":[{"name":"日志收集","slug":"日志收集","permalink":"http://fudali.cc/categories/日志收集/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"http://fudali.cc/tags/ELK/"},{"name":"logstash","slug":"logstash","permalink":"http://fudali.cc/tags/logstash/"}]},{"title":"go 1.6.2 strings split 方法改造","slug":"go1.6.2-strings-split","date":"2016-12-12T16:00:00.000Z","updated":"2017-03-18T04:55:31.000Z","comments":true,"path":"2016/12/13/go1.6.2-strings-split/","link":"","permalink":"http://fudali.cc/2016/12/13/go1.6.2-strings-split/","excerpt":"","text":"当调用strings.Split(s,seq string)时,如果seq连续出现，比如s=&quot; dfdgdfg （多个空格） dfdg （多个空格） hghyjkjuyk &quot;。调用slice:=strings.Split(s,&quot; &quot;)将会出现len(slice)!=3，我认为这并不是大家希望看到的结果。 查看strings.Split(s,seq string)源码：func Split(s, sep string) []string { return genSplit(s, sep, 0, -1) } 接着查看strings.genSplit()源码：12345678910111213141516171819202122232425func genSplit(s, sep string, sepSave, n int) []string &#123; if n == 0 &#123; return nil &#125; if sep == &quot;&quot; &#123; return explode(s, n) &#125; if n &lt; 0 &#123; n = Count(s, sep) + 1 &#125; c := sep[0] start := 0 a := make([]string, n) na := 0 for i := 0; i+len(sep) &lt;= len(s) &amp;&amp; na+1 &lt; n; i++ &#123; if s[i] == c &amp;&amp; (len(sep) == 1 || s[i:i+len(sep)] == sep) &#123; a[na] = s[start : i+sepSave] na++ start = i + len(sep) i += len(sep) - 1 &#125; &#125; a[na] = s[start:] return a[0 : na+1]&#125; 发现并没有做相关的判断就将s[start : i+sepSave]添加到返回数组造成出现这种情况； 顾在for循环中添加一个判断以达到预期返回值，代码如下：123456789if s[i] == c &amp;&amp; (len(sep) == 1 || s[i:i+len(sep)] == sep) &#123; splitStr:=s[start : i+sepSave] if !(splitStr == sep || start==i+sepSave) &#123; a[na] = splitStr na++ &#125; start = i + len(sep) i += len(sep) - 1&#125; 之后调用即可达到预期返回值","categories":[{"name":"golang笔记","slug":"golang笔记","permalink":"http://fudali.cc/categories/golang笔记/"}],"tags":[{"name":"golang","slug":"golang","permalink":"http://fudali.cc/tags/golang/"}]},{"title":"beego upsert 方法原理","slug":"beego-upsert-method","date":"2016-12-12T16:00:00.000Z","updated":"2017-03-18T04:52:13.000Z","comments":true,"path":"2016/12/13/beego-upsert-method/","link":"","permalink":"http://fudali.cc/2016/12/13/beego-upsert-method/","excerpt":"","text":"前言 在beego1.6.1版本orm中并未提供insertOrUpdate，但是自己做项目时遇到了这个需求，顾写了一个自己的实现，暂只支持mysql与postgres。实现原理是数据自带可实现insertorupdate的功能语句。mysql：ON DUPLICATE KEY UPDATEpostgres : ON CONFLICT DO UPDATE SET然后去orm实现中自己拼装sql语句 code 好了，亮代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788func (d *dbBase) InsertOrUpdate(q dbQuerier, mi *modelInfo,ind reflect.Value, tz *time.Location, dn string, args ...string) (int64, error) &#123; iouStr := &quot;&quot; mysql := &quot;mysql&quot; postgres := &quot;postgres&quot; argsMap := map[string]string&#123;&#125; if dn == mysql &#123; iouStr = &quot;ON DUPLICATE KEY UPDATE&quot; &#125; else if dn == postgres &amp;&amp; len(args) &gt; 0 &#123; args0 = args[0] iouStr = fmt.Sprintf(&quot;ON CONFLICT (%s) DO UPDATE SET&quot;, args0) &#125; else &#123; return 0, fmt.Errorf(&quot;`%s` nonsupport insert or update in beego&quot;, dn) &#125; for _, v := range args &#123; kv := strings.Split(v, &quot;=&quot;) if len(kv) == 2 &#123; argsMap[kv[0]] = kv[1] &#125; &#125; isMulti := false names := make([]string, 0, len(mi.fields.dbcols)-1) Q := d.ins.TableQuote() values, err := d.collectValues(mi, ind, mi.fields.dbcols, true, true, &amp;names, tz) if err != nil &#123; return 0, err marks := make([]string, len(names)) updateValues := make([]interface&#123;&#125;, 0) updates := make([]string, len(names)) var conflitValue interface&#123;&#125; for i, v := range names &#123; marks[i] = &quot;?&quot; valueStr := argsMap[v] if v == args0 &#123; conflitValue = values[i] &#125; if valueStr != &quot;&quot; &#123; switch dn &#123; case mysql: updates[i] = v + &quot;=&quot; + valueStr break case postgres: if conflitValue != nil &#123; updates[i] = fmt.Sprintf(&quot;%s=(select %s from %s where %s = ? )&quot;, v, valueStr, mi.table, args[0]) updateValues = append(updateValues, conflitValue) &#125; else &#123; return 0, fmt.Errorf(&quot;`%s` must be in front of `%s` in your struct&quot;, args[0], v) &#125; break &#125; &#125; else &#123; updates[i] = v + &quot;=?&quot; updateValues = append(updateValues, values[i]) &#125; values = append(values, updateValues...) sep := fmt.Sprintf(&quot;%s, %s&quot;, Q, Q) qmarks := strings.Join(marks, &quot;, &quot;) qupdates := strings.Join(updates, &quot;, &quot;) columns := strings.Join(names, sep) multi := len(values) / len(names) if isMulti &#123; qmarks = strings.Repeat(qmarks+&quot;), (&quot;, multi-1) + qmarks &#125; query := fmt.Sprintf(&quot;INSERT INTO %s%s%s (%s%s%s) VALUES (%s) %s &quot;+qupdates, Q, mi.table, Q, Q, columns, Q, qmarks, iouStr) if isMulti || !d.ins.HasReturningID(mi, &amp;query) &#123; res, err := q.Exec(query, values...) if err == nil &#123; if isMulti &#123; return res.RowsAffected() &#125; return res.LastInsertId() &#125; return 0, err &#125; row := q.QueryRow(query, values...) var id int64 err = row.Scan(&amp;id) return id, err&#125; 这就是实现功能的全部逻辑，当然要想在beego orm中使用insertorupdate还有一些其他的工作要做，首先这段代码应该添加在 beego/orm文件夹下的db.go文件中 然后在 orm.go 文件中添加 12345678910 func (o *orm) InsertOrUpdate(md interface&#123;&#125;,colConflitAndArgs ...string) (int64, error) &#123; mi, ind := o.getMiInd(md, true) id, err := o.alias.DbBaser.InsertOrUpdate(o.db, mi, ind, o.alias.TZ, o.alias.DriverName, colConflitAndArgs...) if err != nil &#123; return id, err &#125; o.setPk(mi, ind, id) return id, nil&#125; 123再在types.go文件中的type Ormer interface和type dbBaser interface中分别添加InsertOrUpdate(md interface&#123;&#125;, colConflitAndArgs ...string) (int64, error) 与InsertOrUpdate(dbQuerier, *modelInfo, reflect.Value, *time.Location, string, ...string) (int64, error) 好了，现在大功告成了。可以使用InssertOrUpdate功能了列如： mysql1234567891011121314mysql：func IOUFinish(all *Finish) int64 &#123; db := orm.NewOrm() db.Using(&quot;mysql&quot;) r, e := db.InsertOrUpdate(all, &quot;step=step+1&quot;) if e != nil &#123; fmt.Println(e) return 0 &#125; fmt.Println(r) return r&#125; 这个函数在出入数据时有主键或者唯一键冲突，将执行update操作，其中step列执行+自增操作，其他列按model中的值进行update操作。其中”step=step+1”格式数据可以有多个也可以没有，这种格式只用于自增操作 postgresql1234567891011121314postgres：func IOUFinish(all *Finish) int64 &#123; db := orm.NewOrm() db.Using(&quot;postgres&quot;) r, e := db.InsertOrUpdate(all,&quot;confilctColumnName&quot; &quot;step=step+1&quot;) if e != nil &#123; fmt.Println(e) return 0 &#125; fmt.Println(r) return r&#125; 当操作postgres数据库是，必须在model后的第一个参数指定你预期的冲突列的列名(由于实现此功能的sql语句需要且数据库版本必须大于9.5，因为实现的语句由9.5版本推出)，其他与mysql一致。 提示：在使用自增操作是最好不要自增主键或者唯一键，可能会引起错误。","categories":[{"name":"开源项目","slug":"开源项目","permalink":"http://fudali.cc/categories/开源项目/"}],"tags":[{"name":"golang","slug":"golang","permalink":"http://fudali.cc/tags/golang/"},{"name":"beego","slug":"beego","permalink":"http://fudali.cc/tags/beego/"}]}]}